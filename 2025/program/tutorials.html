<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/2025/_next/static/media/c6bc620d5d278a26-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/2025/images/adc2025-logo.svg"/><link rel="preload" as="image" href="/2025/images/people/Yang-Cao.jpg"/><link rel="preload" as="image" href="/2025/images/people/Blaise-Delattre.jpg"/><link rel="preload" as="image" href="/2025/images/people/Jianzhong-Qi.jpg"/><link rel="preload" as="image" href="/2025/images/people/Feng-Liu.jpeg"/><link rel="preload" as="image" href="/2025/images/people/Zhe-Xue.jpg"/><link rel="stylesheet" href="/2025/_next/static/css/8eaeb22d09b90636.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/2025/_next/static/chunks/webpack-ee9fc34e84752e60.js"/><script src="/2025/_next/static/chunks/4bd1b696-bd86104e46b07b04.js" async=""></script><script src="/2025/_next/static/chunks/684-626f5dea3a2f449b.js" async=""></script><script src="/2025/_next/static/chunks/main-app-677ab25fe50375c6.js" async=""></script><script src="/2025/_next/static/chunks/63-180cf95d3f41d888.js" async=""></script><script src="/2025/_next/static/chunks/app/layout-c55a1c926d93c9fb.js" async=""></script><script src="/2025/_next/static/chunks/874-b3280dfeabc5eb1d.js" async=""></script><script src="/2025/_next/static/chunks/597-54f65f5ef48ebc8f.js" async=""></script><script src="/2025/_next/static/chunks/app/(main)/layout-309699a9df05359d.js" async=""></script><meta name="next-size-adjust" content=""/><title>Tutorials | ADC 2025</title><meta name="description" content="Learn about the tutorials at ADC 2025."/><link rel="manifest" href="/2025/manifest.json"/><meta name="creator" content="ADC2025 Committee"/><meta name="robots" content="index, follow"/><link rel="canonical" href="https://adc-conference.github.io/2025/program/tutorials"/><meta property="og:title" content="ADC 2025 - Australasian Database Conference"/><meta property="og:description" content="Welcome to the 36th Australasian Database Conference, ADC 2025. The Australasian Database Conference (ADC) series is an annual forum for sharing the latest research progresses and novel applications of database systems, data management, data mining and data analytics for researchers and practitioners in these areas from Australia, New Zealand and in the world."/><meta property="og:url" content="https://adc-conference.github.io/2025"/><meta property="og:site_name" content="ADC 2025"/><meta property="og:locale" content="en_AU"/><meta property="og:image" content="https://adc-conference.github.io/2025/thumbnail.jpg"/><meta property="og:image:width" content="2124"/><meta property="og:image:height" content="1536"/><meta property="og:image:alt" content="ADC 2025 - Australasian Database Conference"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="ADC 2025 - Australasian Database Conference"/><meta name="twitter:description" content="Welcome to the 36th Australasian Database Conference, ADC 2025. The Australasian Database Conference (ADC) series is an annual forum for sharing the latest research progresses and novel applications of database systems, data management, data mining and data analytics for researchers and practitioners in these areas from Australia, New Zealand and in the world."/><meta name="twitter:image" content="https://adc-conference.github.io/2025/thumbnail.jpg"/><meta name="twitter:image:width" content="2124"/><meta name="twitter:image:height" content="1536"/><meta name="twitter:image:alt" content="ADC 2025 - Australasian Database Conference"/><link rel="icon" href="/2025/favicon.ico" type="image/x-icon" sizes="48x48"/><link rel="icon" href="/2025/icon0.svg?6301f139932b1e0e" type="image/svg+xml" sizes="any"/><link rel="icon" href="/2025/icon1.png?e3db09bd4030dcd9" type="image/png" sizes="96x96"/><link rel="apple-touch-icon" href="/2025/apple-icon.png?2a84e5a153a42d32" type="image/png" sizes="180x180"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/2025/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_6dda44 subpixel-antialiased min-h-screen flex flex-col"><main class="flex-1"><header class="mb-6 bg-gray-900 fixed top-0 z-20 w-full"><div class="flex justify-between items-center max-w-[70em] mx-auto h-[4em] pr-3.5 pl-5 md:pl-8 lg:pl-10"><div class="pt-0.5"><a class="flex items-center" href="/2025"><img alt="ADC 2025 Logo" width="170" height="50" decoding="async" data-nimg="1" class="mr-2" style="color:transparent" src="/2025/images/adc2025-logo.svg"/></a></div><div class="flex text-gray-100"><nav class="hidden md:flex top-0 z-20 bg-none justify-end items-center transition-normal duration-500
       false pr-3"><div class="false"><ul class="flex items-center justify-center"><li><a class="px-6 py-4 uppercase font-bold text-sm hover:text-primary
                      transition-colors tracking-wider hidden lg:block" href="/2025">Home</a></li><li class="relative group"><button class="px-3 py-4 uppercase font-bold text-sm flex items-center group-hover:text-primary cursor-pointer transition-colors tracking-wider">Submission<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-4 h-4 ml-0.5"><path stroke-linecap="round" stroke-linejoin="round" d="m19.5 8.25-7.5 7.5-7.5-7.5"></path></svg></button><ul class="
                  absolute left-0 top-full w-48 bg-white shadow-lg rounded p-1
                  divide-y divide-gray-100
                  transition-opacity duration-200 ease-out
                  opacity-0 pointer-events-none
                "><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            rounded-t
                            " href="/2025/research-track">Research Track</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/encore-track">Encore Track</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/shepherding-track">Shepherding Track</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/call-for-tutorials">Call for Tutorials</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/call-for-workshops">Call for Workshops</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/call-for-3mt">Call for Three-Minute Thesis Participants</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            rounded-b" href="/2025/camera-ready-instructions">Camera-Ready Instructions</a></li></ul></li><li class="relative group"><button class="px-3 py-4 uppercase font-bold text-sm flex items-center group-hover:text-primary cursor-pointer transition-colors tracking-wider">Program<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-4 h-4 ml-0.5"><path stroke-linecap="round" stroke-linejoin="round" d="m19.5 8.25-7.5 7.5-7.5-7.5"></path></svg></button><ul class="
                  absolute left-0 top-full w-48 bg-white shadow-lg rounded p-1
                  divide-y divide-gray-100
                  transition-opacity duration-200 ease-out
                  opacity-0 pointer-events-none
                "><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            rounded-t
                            " href="/2025/program/program-sydney">Program - Sydney</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/program/program-bali">Program - Bali</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/program/keynote-talks">Keynote Talks</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/program/tutorials">Tutorials</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/program/invited-talks">Invited Talks</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            rounded-b" href="/2025/program/accepted-papers">Accepted Papers</a></li></ul></li><li class="relative group"><button class="px-3 py-4 uppercase font-bold text-sm flex items-center group-hover:text-primary cursor-pointer transition-colors tracking-wider">Attend<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-4 h-4 ml-0.5"><path stroke-linecap="round" stroke-linejoin="round" d="m19.5 8.25-7.5 7.5-7.5-7.5"></path></svg></button><ul class="
                  absolute left-0 top-full w-48 bg-white shadow-lg rounded p-1
                  divide-y divide-gray-100
                  transition-opacity duration-200 ease-out
                  opacity-0 pointer-events-none
                "><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            rounded-t
                            " href="/2025/attend/venue">Venue</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/attend/accommodation">Accommodation</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/attend/registration">Registration</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            " href="/2025/attend/student-travel-awards">Student Travel Awards</a></li><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            
                            rounded-b" href="/2025/attend/visa-information">Visa Information</a></li></ul></li><li class="relative group"><button class="px-3 py-4 uppercase font-bold text-sm flex items-center group-hover:text-primary cursor-pointer transition-colors tracking-wider">Organisation<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-4 h-4 ml-0.5"><path stroke-linecap="round" stroke-linejoin="round" d="m19.5 8.25-7.5 7.5-7.5-7.5"></path></svg></button><ul class="
                  absolute left-0 top-full w-48 bg-white shadow-lg rounded p-1
                  divide-y divide-gray-100
                  transition-opacity duration-200 ease-out
                  opacity-0 pointer-events-none
                "><li><a class="block px-4 py-2 text-sm font-medium text-black hover:bg-gray-100
                            rounded-t
                            " href="/2025/organisation">Organising Committee</a></li><li><span class="block px-4 py-2 text-sm font-medium text-gray-400 cursor-not-allowed rounded">Program Committee</span></li></ul></li></ul></div></nav><nav class="md:hidden absolute right-0 top-0 z-30 false"><div class="flex items-center justify-end h-16 px-4 false false"><button aria-label="Open menu" class="p-4 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" d="M3.75 6.75h16.5M3.75 12h16.5m-16.5 5.25h16.5"></path></svg></button></div></nav></div></div></header><main class="max-w-[70em] w-full mx-auto px-5 pt-[6em] md:pt-[8em] md:px-8 lg:px-10"><div><h2 class="text-3xl font-bold mb-2">Tutorials</h2><div class="w-[4em] h-[5px] bg-gradient-to-r from-primary from-30% to-secondary mb-10"></div><article class="pb-10"><section><p class="text-primary uppercase tracking-[0.2em] mb-2 font-semibold">Tutorial <!-- -->1</p><h3 class="font-bold text-2xl mb-2 text-gray-600 leading-9">Robust Certificates for Neural Networks</h3><ul class="text-sm mt-6 mb-6 list-disc list-inside"><li><span class="font-semibold inline md:min-w-30 md:inline-block">Venue:</span> <!-- -->Bali (in-person)</li><li><span class="font-semibold inline md:min-w-30 md:inline-block">Bali Time:</span> <!-- -->Fri, 5 Dec 2025 13:30 - 14:30 WITA (UTC+8)</li></ul><p class="">Deep neural networks face the critical challenge of adversarial vulnerability: imperceptible perturbations can drastically alter predictions. Empirical defenses, such as adversarial training, improve robustness against known attacks but often fail under stronger or adaptive adversaries. In contrast, certified robustness provides provable guarantees that a model’s prediction remains stable within a prescribed perturbation region. This tutorial introduces two complementary approaches: Lipschitz-constrained networks, which enforce global sensitivity bounds via spectral norm regularization, convex potentials, and contractive architectures, yielding deterministic certificates; and randomized smoothing, a probabilistic method that transforms any classifier into a certifiably robust model by adding Gaussian noise and averaging predictions. We will also highlight applications across natural language processing, datacentric AI, and foundation models, illustrating how certification principles extend to robustness against diverse perturbations, data quality issues, and large-scale multimodal systems.</p><div class="flex items-center space-x-2 mt-6"><div class="w-0 h-0 border-t-[0.6em] border-t-transparent border-l-[1em] border-gray-600 border-b-[0.6em] border-b-transparent"></div><h3 class="font-bold text-xl text-gray-600">Speaker<!-- -->s</h3></div><div class="flex flex-col"><div class="bg-gray-100 mt-4 rounded-xl min-w-[20rem]"><a href="https://yangcao888.github.io/" target="_blank" rel="noopener" class="flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl"><img src="/2025/images/people/Yang-Cao.jpg" alt="Yang Cao" class="w-32 h-32 rounded-tl-xl object-cover shadow-lg"/></a><a href="https://yangcao888.github.io/" target="_blank" rel="noopener" class="flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300"><h4 class="font-bold text-[1.2em]">Yang Cao</h4><p class="text-gray-500 font-medium text-[0.95em]">Institute of Science Tokyo</p></a><p class="text-gray-600 text-[0.9em] px-4 pb-4"><a href="https://yangcao888.github.io/" target="_blank" rel="noopener" class="hover:text-primary transition-colors duration-300">Yang Cao</a> <!-- -->is an Associate Professor at the Department of Computer Science, Institute of Science Tokyo (Science Tokyo, formerly Tokyo Tech), and directing the Trustworthy Data Science and AI (TDSAI) Lab. He is passionate about studying and teaching on algorithmic trustworthiness in data science and AI. Two of his papers on data privacy were selected as best paper finalists in top- tier conferences IEEE ICDE 2017 and ICME 2020. He was a recipient of the IEEE Computer Society Japan Chapter Young Author Award 2019, Database Society of Japan Kambayashi Young Researcher Award 2021. His research projects were/are supported by JSPS, JST, MSRA, KDDI, LINE, WeBank, etc.</p></div><div class="bg-gray-100 mt-4 rounded-xl min-w-[20rem]"><a href="https://www.lamsade.dauphine.fr/~bdelattre/" target="_blank" rel="noopener" class="flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl"><img src="/2025/images/people/Blaise-Delattre.jpg" alt="Blaise Delattre" class="w-32 h-32 rounded-tl-xl object-cover shadow-lg"/></a><a href="https://www.lamsade.dauphine.fr/~bdelattre/" target="_blank" rel="noopener" class="flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300"><h4 class="font-bold text-[1.2em]">Blaise Delattre</h4><p class="text-gray-500 font-medium text-[0.95em]">Institute of Science Tokyo</p></a><p class="text-gray-600 text-[0.9em] px-4 pb-4"><a href="https://www.lamsade.dauphine.fr/~bdelattre/" target="_blank" rel="noopener" class="hover:text-primary transition-colors duration-300">Blaise Delattre</a> <!-- -->is a Postdoctoral Researcher in the TDSAI Lab, working with Prof. Yang Cao. He received his PhD in Computer Science from PSL University, where his research focused on certified adversarial robustness of deep neural networks, with contributions on Lipschitz-constrained architectures and randomized smoothing. His current interests focus on robustness and reliability of large language, vision–language, and other foundation models.</p></div></div><div class="w-[5.9em] h-[5px] bg-gradient-to-r from-primary from-30% to-secondary mt-14 mb-6"></div></section><section><p class="text-primary uppercase tracking-[0.2em] mb-2 font-semibold">Tutorial <!-- -->2</p><h3 class="font-bold text-2xl mb-2 text-gray-600 leading-9">Question Answering over Knowledge Bases in the Era of Large Language Models</h3><ul class="text-sm mt-6 mb-6 list-disc list-inside"><li><span class="font-semibold inline md:min-w-30 md:inline-block">Venue:</span> <!-- -->Sydney (in-person), Bali (broadcast)</li><li><span class="font-semibold inline md:min-w-30 md:inline-block">Sydney Time:</span> <!-- -->Sat, 6 Dec 2025 13:00 - 14:00 AEDT (UTC+11)</li><li><span class="font-semibold inline md:min-w-30 md:inline-block">Bali Time:</span> <!-- -->Sat, 6 Dec 2025 10:00 - 11:00 WITA (UTC+8)</li></ul><p class="">Knowledge Base Question Answering (KBQA) has emerged as a crucial paradigm for providing accurate, explainable, and domain-specific answers to natural language queries. With the rapid advancement of Large Language Models (LLMs), QA systems can leverage their powerful language understanding and generation capabilities. However, LLMs often struggle with hallucination, static knowledge, and limited interpretability. Integrating structured Knowledge Bases (KBs) addresses these limitations by providing explicit, updatable, and domain-specific factual knowledge. This tutorial provides an overview of KBQA in the era of LLMs. We introduce fundamental concepts of KBQA, discuss the strengths and limitations of LLMs and KBs, and survey state-of-the-art methods, including retrieval-augmented generation and knowledge integration approaches. Practical considerations, applications, and limitations are highlighted throughout.</p><div class="flex items-center space-x-2 mt-6"><div class="w-0 h-0 border-t-[0.6em] border-t-transparent border-l-[1em] border-gray-600 border-b-[0.6em] border-b-transparent"></div><h3 class="font-bold text-xl text-gray-600">Speaker</h3></div><div class="flex flex-col"><div class="bg-gray-100 mt-4 rounded-xl min-w-[20rem]"><a href="https://jianzhongqi.github.io/" target="_blank" rel="noopener" class="flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl"><img src="/2025/images/people/Jianzhong-Qi.jpg" alt="Jianzhong Qi" class="w-32 h-32 rounded-tl-xl object-cover shadow-lg"/></a><a href="https://jianzhongqi.github.io/" target="_blank" rel="noopener" class="flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300"><h4 class="font-bold text-[1.2em]">Jianzhong Qi</h4><p class="text-gray-500 font-medium text-[0.95em]">The University of Melbourne</p></a><p class="text-gray-600 text-[0.9em] px-4 pb-4"><a href="https://jianzhongqi.github.io/" target="_blank" rel="noopener" class="hover:text-primary transition-colors duration-300">Jianzhong Qi</a> <!-- -->is an Associate Professor at The University of Melbourne and an ARC Future Fellow. His research concerns fundamental algorithms for management of and knowledge discovery from structured and semi-structured data. He has served as a PC Chair for the Australasian Database  Conference in 2020, and he has served as an Area Chair, Senior PC member, and PC member for top machine learning and database venues such as ICML, NeurIPS, ICLR, SIGMOD, ICDE and WWW.</p></div></div><div class="w-[5.9em] h-[5px] bg-gradient-to-r from-primary from-30% to-secondary mt-14 mb-6"></div></section><section><p class="text-primary uppercase tracking-[0.2em] mb-2 font-semibold">Tutorial <!-- -->3</p><h3 class="font-bold text-2xl mb-2 text-gray-600 leading-9">Neural Network Reprogrammability: A Unified Framework for Parameter-Efficient Foundation Model Adaptation</h3><ul class="text-sm mt-6 mb-6 list-disc list-inside"><li><span class="font-semibold inline md:min-w-30 md:inline-block">Venue:</span> <!-- -->Bali (in-person), Sydney (broadcast)</li><li><span class="font-semibold inline md:min-w-30 md:inline-block">Sydney Time:</span> <!-- -->Sat, 6 Dec 2025 14:00 - 15:00 AEDT (UTC+11)</li><li><span class="font-semibold inline md:min-w-30 md:inline-block">Bali Time:</span> <!-- -->Sat, 6 Dec 2025 11:00 - 12:00 WITA (UTC+8)</li></ul><p class="">The goal of this tutorial is to provide machine learning researchers and practitioners with a clear guideline for adapting Foundation Models in the context of parameter-efficient fine-tuning (PEFT). This tutorial moves beyond a simple catalog of PEFT techniques to introduce Neural Network Reprogrammability as a unifying framework that explains how and why modern PEFT methods work. The audience will learn to view techniques, e.g., prompt tuning, in-context learning, and model reprogramming, not as isolated methodologies, but as principled instances of a shared underlying idea: repurposing a fixed pre-trained model by strategically manipulating information at its interfaces. Attendees will walk away with a structured understanding of the adaptation lifecycle: from input manipulation to output alignment. The tutorial will synthesize existing methodologies and practical applications with a cohesive principle, enabling attendees to better analyze, choose, and design adaptation strategies for their own projects, without incurring substantial costs when fine-tuning Foundation Models.</p><div class="flex items-center space-x-2 mt-6"><div class="w-0 h-0 border-t-[0.6em] border-t-transparent border-l-[1em] border-gray-600 border-b-[0.6em] border-b-transparent"></div><h3 class="font-bold text-xl text-gray-600">Speaker</h3></div><div class="flex flex-col"><div class="bg-gray-100 mt-4 rounded-xl min-w-[20rem]"><a href="https://fengliu90.github.io/" target="_blank" rel="noopener" class="flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl"><img src="/2025/images/people/Feng-Liu.jpeg" alt="Feng Liu" class="w-32 h-32 rounded-tl-xl object-cover shadow-lg"/></a><a href="https://fengliu90.github.io/" target="_blank" rel="noopener" class="flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300"><h4 class="font-bold text-[1.2em]">Feng Liu</h4><p class="text-gray-500 font-medium text-[0.95em]">The University of Melbourne</p></a><p class="text-gray-600 text-[0.9em] px-4 pb-4"><a href="https://fengliu90.github.io/" target="_blank" rel="noopener" class="hover:text-primary transition-colors duration-300">Feng Liu</a> <!-- -->is a Senior Lecturer in Machine Learning and ARC DECRA Fellow at The University of Melbourne, where he directs the Trustworthy Machine Learning and Reasoning Lab. He is also a Visiting Scientist at RIKEN AIP. His research focuses on hypothesis testing and trustworthy machine learning. He has served as an area chair for ICML, NeurIPS, ICLR, and AISTATS, and as an editor or action editor for several leading journals. His work has been recognized with the NeurIPS 2022 Outstanding Paper Award and multiple Outstanding Reviewer Awards.</p></div></div><div class="w-[5.9em] h-[5px] bg-gradient-to-r from-primary from-30% to-secondary mt-14 mb-6"></div></section><section><p class="text-primary uppercase tracking-[0.2em] mb-2 font-semibold">Tutorial <!-- -->4</p><h3 class="font-bold text-2xl mb-2 text-gray-600 leading-9">Optimizing Quality and Efficiency in Federated Learning</h3><ul class="text-sm mt-6 mb-6 list-disc list-inside"><li><span class="font-semibold inline md:min-w-30 md:inline-block">Venue:</span> <!-- -->Bali (in-person), Sydney (broadcast)</li><li><span class="font-semibold inline md:min-w-30 md:inline-block">Sydney Time:</span> <!-- -->Sat, 6 Dec 2025 15:30 - 16:30 AEDT (UTC+11)</li><li><span class="font-semibold inline md:min-w-30 md:inline-block">Bali Time:</span> <!-- -->Sat, 6 Dec 2025 12:30 - 13:30 WITA (UTC+8)</li></ul><p class="">Federated Learning (FL) faces critical challenges in model generalization and  Non-IID data, which impact both the quality and efficiency of the learned models. This talk will present some advancements to address these issues. We first introduce a reinforcement federated domain generalization method, which uses a reinforcement learning agent to dynamically optimize feature representation for superior performance on unseen data domains. Next, we present a method to create privacy-preserving client data, effectively mitigating data heterogeneity. Finally, we describe a classifier debiased federated learning framework that directly corrects classifier bias from Non-IID data. Together, these approaches form a cohesive strategy for building more robust, accurate, and efficient FL systems.</p><div class="flex items-center space-x-2 mt-6"><div class="w-0 h-0 border-t-[0.6em] border-t-transparent border-l-[1em] border-gray-600 border-b-[0.6em] border-b-transparent"></div><h3 class="font-bold text-xl text-gray-600">Speaker</h3></div><div class="flex flex-col"><div class="bg-gray-100 mt-4 rounded-xl min-w-[20rem]"><a href="https://teacher.bupt.edu.cn/xuezhe/en/index.htm" target="_blank" rel="noopener" class="flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl"><img src="/2025/images/people/Zhe-Xue.jpg" alt="Zhe Xue" class="w-32 h-32 rounded-tl-xl object-cover shadow-lg"/></a><a href="https://teacher.bupt.edu.cn/xuezhe/en/index.htm" target="_blank" rel="noopener" class="flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300"><h4 class="font-bold text-[1.2em]">Zhe Xue</h4><p class="text-gray-500 font-medium text-[0.95em]">Beijing University of Posts and Telecommunications</p></a><p class="text-gray-600 text-[0.9em] px-4 pb-4"><a href="https://teacher.bupt.edu.cn/xuezhe/en/index.htm" target="_blank" rel="noopener" class="hover:text-primary transition-colors duration-300">Zhe Xue</a> <!-- -->is a Professor at Beijing University of Posts and Telecommunications, specializing in data mining, multimodal learning, and federated learning. He has published many papers in top-tier journals and conferences such as ICML, NeurIPS, CVPR, AAAI, IJCAI, MM and WWW. His major honors include the IEEE CCIS Best Paper Award, IEEE BigComp Best Paper Award Runner-up, CCFAI Best Paper Award, and ChinaMM Best Student Paper Award.</p></div></div></section></article></div><!--$--><!--/$--><!--$--><!--/$--></main></main><footer class="w-full bg-gray-100 mt-16"><div class="max-w-[70em] mx-auto py-12 w-full"><div class="mx-5 gap-y-2 px-0 lg:px-5 text-gray-600"><div class="mb-4"><div class="text-[0.8rem] flex flex-col md:flex-row"><a class="flex items-center hover:decoration-solid text-[0.8rem] underline decoration-dotted" href="https://www.springernature.com/gp/authors/book-authors-code-of-conduct" target="_blank" rel="noreferrer">Code of Conduct</a><span class="hidden md:block text-gray-400 mx-1">·</span><div class="flex"><span>Previous proceedings on </span><a class="flex items-center hover:underline text-[0.8rem]" href="https://link.springer.com/conference/adc" target="_blank" rel="noreferrer"><span class="underline decoration-dotted">SpringerLink</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-3 h-3 ml-1"><path fill-rule="evenodd" d="M4.25 5.5a.75.75 0 00-.75.75v8.5c0 .414.336.75.75.75h8.5a.75.75 0 00.75-.75v-4a.75.75 0 011.5 0v4A2.25 2.25 0 0112.75 17h-8.5A2.25 2.25 0 012 14.75v-8.5A2.25 2.25 0 014.25 4h5a.75.75 0 010 1.5h-5z" clip-rule="evenodd"></path><path fill-rule="evenodd" d="M6.194 12.753a.75.75 0 001.06.053L16.5 4.44v2.81a.75.75 0 001.5 0v-4.5a.75.75 0 00-.75-.75h-4.5a.75.75 0 000 1.5h2.553l-9.056 8.194a.75.75 0 00-.053 1.06z" clip-rule="evenodd"></path></svg></a></div></div></div><div class="text-[0.8rem] flex flex-col md:flex-row items-start justify-between"><div><ul class="grid grid-cols-2 md:flex flex-wrap gap-x-10 md:gap-x-1 gap-y-2 md:gap-y-1 items-center mb-4 md:mb-1"><li class="text-sm flex items-center"><a href="https://adc-conference.github.io/2024/" target="_blank" rel="noreferrer" class="text-gray-600 flex items-center text-[0.8rem] underline decoration-dotted hover:decoration-solid"><span>2024 Gold Coast &amp; Tokyo</span></a></li><li class="text-sm flex items-center"><span class="hidden md:block text-gray-400 mr-1">·</span><a href="https://adc2023.github.io/" target="_blank" rel="noreferrer" class="text-gray-600 flex items-center text-[0.8rem] underline decoration-dotted hover:decoration-solid"><span>2023 Melbourne</span></a></li><li class="text-sm flex items-center"><span class="hidden md:block text-gray-400 mr-1">·</span><a href="https://adc2022.github.io/index.html" target="_blank" rel="noreferrer" class="text-gray-600 flex items-center text-[0.8rem] underline decoration-dotted hover:decoration-solid"><span>2022 Sydney</span></a></li><li class="text-sm flex items-center"><span class="hidden md:block text-gray-400 mr-1">·</span><a href="https://adc2021.github.io/" target="_blank" rel="noreferrer" class="text-gray-600 flex items-center text-[0.8rem] underline decoration-dotted hover:decoration-solid"><span>2021 Dunedin</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="w-3 h-3 ml-1"><path fill-rule="evenodd" d="M4.25 5.5a.75.75 0 00-.75.75v8.5c0 .414.336.75.75.75h8.5a.75.75 0 00.75-.75v-4a.75.75 0 011.5 0v4A2.25 2.25 0 0112.75 17h-8.5A2.25 2.25 0 012 14.75v-8.5A2.25 2.25 0 014.25 4h5a.75.75 0 010 1.5h-5z" clip-rule="evenodd"></path><path fill-rule="evenodd" d="M6.194 12.753a.75.75 0 001.06.053L16.5 4.44v2.81a.75.75 0 001.5 0v-4.5a.75.75 0 00-.75-.75h-4.5a.75.75 0 000 1.5h2.553l-9.056 8.194a.75.75 0 00-.053 1.06z" clip-rule="evenodd"></path></svg></a></li></ul><span class="font-[Arial]">©</span> 1990-2025 Australasian Database Conference.<br class="block sm:hidden"/> All Rights Reserved.<span class="mt-4 hidden">Cover photo by Johnny Bhalla and Melvin Melvin on Unsplash.</span></div><div class="flex flex-col items-start md:items-end"><div class="mt-2 flex items-center gap-2 md:gap-1"><a href="https://x.com/ADC_conf" target="_blank" rel="noreferrer" aria-label="ADC on X (Twitter)" class="text-gray-400 hover:text-black transition-colors" title="X (Twitter)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" fill="currentColor" class="w-10 h-10 md:w-8 md:h-8"><path d="M 11 4 C 7.134 4 4 7.134 4 11 L 4 39 C 4 42.866 7.134 46 11 46 L 39 46 C 42.866 46 46 42.866 46 39 L 46 11 C 46 7.134 42.866 4 39 4 L 11 4 z M 13.085938 13 L 21.023438 13 L 26.660156 21.009766 L 33.5 13 L 36 13 L 27.789062 22.613281 L 37.914062 37 L 29.978516 37 L 23.4375 27.707031 L 15.5 37 L 13 37 L 22.308594 26.103516 L 13.085938 13 z M 16.914062 15 L 31.021484 35 L 34.085938 35 L 19.978516 15 L 16.914062 15 z"></path></svg></a><a href="https://www.linkedin.com/in/adc-conf" target="_blank" rel="noreferrer" aria-label="ADC on LinkedIn" class="text-gray-400 hover:text-[#0A66C2] transition-colors" title="LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="-1 3.6 25 25" fill="currentColor" class="w-10 h-10 md:w-8 md:h-8"><path d="M0 8.219v15.563c0 1.469 1.156 2.625 2.625 2.625h15.563c0.719 0 1.406-0.344 1.844-0.781 0.469-0.469 0.781-1.063 0.781-1.844v-15.563c0-1.469-1.156-2.625-2.625-2.625h-15.563c-0.781 0-1.375 0.313-1.844 0.781-0.438 0.438-0.781 1.125-0.781 1.844zM2.813 10.281c0-1 0.813-1.875 1.813-1.875 1.031 0 1.875 0.875 1.875 1.875 0 1.031-0.844 1.844-1.875 1.844-1 0-1.813-0.813-1.813-1.844zM7.844 23.125v-9.531c0-0.219 0.219-0.406 0.375-0.406h2.656c0.375 0 0.375 0.438 0.375 0.719 0.75-0.75 1.719-0.938 2.719-0.938 2.438 0 4 1.156 4 3.719v6.438c0 0.219-0.188 0.406-0.375 0.406h-2.75c-0.219 0-0.375-0.219-0.375-0.406v-5.813c0-0.969-0.281-1.5-1.375-1.5-1.375 0-1.719 0.906-1.719 2.125v5.188c0 0.219-0.219 0.406-0.438 0.406h-2.719c-0.156 0-0.375-0.219-0.375-0.406zM2.875 23.125v-9.531c0-0.219 0.219-0.406 0.375-0.406h2.719c0.25 0 0.406 0.156 0.406 0.406v9.531c0 0.219-0.188 0.406-0.406 0.406h-2.719c-0.188 0-0.375-0.219-0.375-0.406z"></path></svg></a></div></div></div></div></div></footer><script type="application/ld+json">{"@context":"https://schema.org","@type":"WebSite","name":"ADC 2025 - Australasian Database Conference","description":"Welcome to the 36th Australasian Database Conference, ADC 2025. The Australasian Database Conference (ADC) series is an annual forum for sharing the latest research progresses and novel applications of database systems, data management, data mining and data analytics for researchers and practitioners in these areas from Australia, New Zealand and in the world.","url":"https://adc-conference.github.io/2025"}</script><script src="/2025/_next/static/chunks/webpack-ee9fc34e84752e60.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n4:I[3539,[\"63\",\"static/chunks/63-180cf95d3f41d888.js\",\"177\",\"static/chunks/app/layout-c55a1c926d93c9fb.js\"],\"default\"]\n5:I[6531,[\"63\",\"static/chunks/63-180cf95d3f41d888.js\",\"177\",\"static/chunks/app/layout-c55a1c926d93c9fb.js\"],\"default\"]\n6:I[1766,[\"63\",\"static/chunks/63-180cf95d3f41d888.js\",\"177\",\"static/chunks/app/layout-c55a1c926d93c9fb.js\"],\"default\"]\n7:I[6874,[\"63\",\"static/chunks/63-180cf95d3f41d888.js\",\"874\",\"static/chunks/874-b3280dfeabc5eb1d.js\",\"597\",\"static/chunks/597-54f65f5ef48ebc8f.js\",\"76\",\"static/chunks/app/(main)/layout-309699a9df05359d.js\"],\"\"]\n8:I[3063,[\"63\",\"static/chunks/63-180cf95d3f41d888.js\",\"874\",\"static/chunks/874-b3280dfeabc5eb1d.js\",\"597\",\"static/chunks/597-54f65f5ef48ebc8f.js\",\"76\",\"static/chunks/app/(main)/layout-309699a9df05359d.js\"],\"Image\"]\n9:I[3532,[\"63\",\"static/chunks/63-180cf95d3f41d888.js\",\"874\",\"static/chunks/874-b3280dfeabc5eb1d.js\",\"597\",\"static/chunks/597-54f65f5ef48ebc8f.js\",\"76\",\"static/chunks/app/(main)/layout-309699a9df05359d.js\"],\"default\"]\nc:I[9665,[],\"MetadataBoundary\"]\ne:I[9665,[],\"OutletBoundary\"]\n11:I[4911,[],\"AsyncMetadataOutlet\"]\n13:I[9665,[],\"ViewportBoundary\"]\n15:I[6614,[],\"\"]\n:HL[\"/2025/_next/static/media/c6bc620d5d278a26-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/2025/_next/static/css/8eaeb22d09b90636.css\",\"style\"]\na:T454,Deep neural networks face the critical challenge of adversarial vulnerability: imperceptible perturbations can drastically alter predictions. Empirical defenses, such as adversarial training, improve robustness against known attacks but often fail under stronger or adaptive adversaries. In contrast, certified robustness provides provable guarantees that a model’s prediction remains stable within a prescribed perturbation region. This tutorial introduces two complementary approaches: Lipschitz-constrained networks, which enforce global sensitivity bounds via spectral norm regularization, convex potentials, and contractive architectures, yielding deterministic certific"])</script><script>self.__next_f.push([1,"ates; and randomized smoothing, a probabilistic method that transforms any classifier into a certifiably robust model by adding Gaussian noise and averaging predictions. We will also highlight applications across natural language processing, datacentric AI, and foundation models, illustrating how certification principles extend to robustness against diverse perturbations, data quality issues, and large-scale multimodal systems.b:T445,The goal of this tutorial is to provide machine learning researchers and practitioners with a clear guideline for adapting Foundation Models in the context of parameter-efficient fine-tuning (PEFT). This tutorial moves beyond a simple catalog of PEFT techniques to introduce Neural Network Reprogrammability as a unifying framework that explains how and why modern PEFT methods work. The audience will learn to view techniques, e.g., prompt tuning, in-context learning, and model reprogramming, not as isolated methodologies, but as principled instances of a shared underlying idea: repurposing a fixed pre-trained model by strategically manipulating information at its interfaces. Attendees will walk away with a structured understanding of the adaptation lifecycle: from input manipulation to output alignment. The tutorial will synthesize existing methodologies and practical applications with a cohesive principle, enabling attendees to better analyze, choose, and design adaptation strategies for their own projects, without incurring substantial costs when fine-tuning Foundation Models."])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"eIcBK8p1kBRMvkovuV3jq\",\"p\":\"/2025\",\"c\":[\"\",\"program\",\"tutorials\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"(main)\",{\"children\":[\"program\",{\"children\":[\"tutorials\",{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/2025/_next/static/css/8eaeb22d09b90636.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_6dda44 subpixel-antialiased min-h-screen flex flex-col\",\"children\":[[\"$\",\"main\",null,{\"className\":\"flex-1\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"$L4\",null,{}],[\"$\",\"$L5\",null,{}],[\"$\",\"$L6\",null,{}],[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"WebSite\\\",\\\"name\\\":\\\"ADC 2025 - Australasian Database Conference\\\",\\\"description\\\":\\\"Welcome to the 36th Australasian Database Conference, ADC 2025. The Australasian Database Conference (ADC) series is an annual forum for sharing the latest research progresses and novel applications of database systems, data management, data mining and data analytics for researchers and practitioners in these areas from Australia, New Zealand and in the world.\\\",\\\"url\\\":\\\"https://adc-conference.github.io/2025\\\"}\"}}]]}]}]]}],{\"children\":[\"(main)\",[\"$\",\"$1\",\"c\",{\"children\":[null,[[\"$\",\"header\",null,{\"className\":\"mb-6 bg-gray-900 fixed top-0 z-20 w-full\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex justify-between items-center max-w-[70em] mx-auto h-[4em] pr-3.5 pl-5 md:pl-8 lg:pl-10\",\"children\":[[\"$\",\"div\",null,{\"className\":\"pt-0.5\",\"children\":[\"$\",\"$L7\",null,{\"href\":\"/\",\"className\":\"flex items-center\",\"children\":[\"$\",\"$L8\",null,{\"priority\":true,\"src\":\"/2025/images/adc2025-logo.svg\",\"alt\":\"ADC 2025 Logo\",\"width\":170,\"height\":50,\"className\":\"mr-2\"}]}]}],[\"$\",\"div\",null,{\"className\":\"flex text-gray-100\",\"children\":[\"$\",\"$L9\",null,{}]}]]}]}],[\"$\",\"main\",null,{\"className\":\"max-w-[70em] w-full mx-auto px-5 pt-[6em] md:pt-[8em] md:px-8 lg:px-10\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:0:props:children:props:notFound:0:1:props:style\",\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:0:props:children:props:notFound:0:1:props:children:props:children:1:props:style\",\"children\":404}],[\"$\",\"div\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:0:props:children:props:notFound:0:1:props:children:props:children:2:props:style\",\"children\":[\"$\",\"h2\",null,{\"style\":\"$0:f:0:1:1:props:children:1:props:children:props:children:0:props:children:props:notFound:0:1:props:children:props:children:2:props:children:props:style\",\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]]}],{\"children\":[\"program\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"tutorials\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-3xl font-bold mb-2\",\"children\":\"Tutorials\"}],[\"$\",\"div\",null,{\"className\":\"w-[4em] h-[5px] bg-gradient-to-r from-primary from-30% to-secondary mb-10\"}],[\"$\",\"article\",null,{\"className\":\"pb-10\",\"children\":[[\"$\",\"section\",\"1\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"text-primary uppercase tracking-[0.2em] mb-2 font-semibold\",\"children\":[\"Tutorial \",1]}],[\"$\",\"h3\",null,{\"className\":\"font-bold text-2xl mb-2 text-gray-600 leading-9\",\"children\":\"Robust Certificates for Neural Networks\"}],[\"$\",\"ul\",null,{\"className\":\"text-sm mt-6 mb-6 list-disc list-inside\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Venue:\"}],\" \",\"Bali (in-person)\"]}],\"$undefined\",[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Bali Time:\"}],\" \",\"Fri, 5 Dec 2025 13:30 - 14:30 WITA (UTC+8)\"]}]]}],[\"$\",\"p\",null,{\"className\":\"\",\"children\":\"$a\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center space-x-2 mt-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-0 h-0 border-t-[0.6em] border-t-transparent border-l-[1em] border-gray-600 border-b-[0.6em] border-b-transparent\"}],[\"$\",\"h3\",null,{\"className\":\"font-bold text-xl text-gray-600\",\"children\":[\"Speaker\",\"s\"]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"bg-gray-100 mt-4 rounded-xl min-w-[20rem]\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://yangcao888.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl\",\"children\":[\"$\",\"img\",null,{\"src\":\"/2025/images/people/Yang-Cao.jpg\",\"alt\":\"Yang Cao\",\"className\":\"w-32 h-32 rounded-tl-xl object-cover shadow-lg\"}]}],[\"$\",\"a\",null,{\"href\":\"https://yangcao888.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-bold text-[1.2em]\",\"children\":\"Yang Cao\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-500 font-medium text-[0.95em]\",\"children\":\"Institute of Science Tokyo\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 text-[0.9em] px-4 pb-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://yangcao888.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"hover:text-primary transition-colors duration-300\",\"children\":\"Yang Cao\"}],\" \",\"is an Associate Professor at the Department of Computer Science, Institute of Science Tokyo (Science Tokyo, formerly Tokyo Tech), and directing the Trustworthy Data Science and AI (TDSAI) Lab. He is passionate about studying and teaching on algorithmic trustworthiness in data science and AI. Two of his papers on data privacy were selected as best paper finalists in top- tier conferences IEEE ICDE 2017 and ICME 2020. He was a recipient of the IEEE Computer Society Japan Chapter Young Author Award 2019, Database Society of Japan Kambayashi Young Researcher Award 2021. His research projects were/are supported by JSPS, JST, MSRA, KDDI, LINE, WeBank, etc.\"]}]]}],[\"$\",\"div\",\"1\",{\"className\":\"bg-gray-100 mt-4 rounded-xl min-w-[20rem]\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://www.lamsade.dauphine.fr/~bdelattre/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl\",\"children\":[\"$\",\"img\",null,{\"src\":\"/2025/images/people/Blaise-Delattre.jpg\",\"alt\":\"Blaise Delattre\",\"className\":\"w-32 h-32 rounded-tl-xl object-cover shadow-lg\"}]}],[\"$\",\"a\",null,{\"href\":\"https://www.lamsade.dauphine.fr/~bdelattre/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-bold text-[1.2em]\",\"children\":\"Blaise Delattre\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-500 font-medium text-[0.95em]\",\"children\":\"Institute of Science Tokyo\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 text-[0.9em] px-4 pb-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://www.lamsade.dauphine.fr/~bdelattre/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"hover:text-primary transition-colors duration-300\",\"children\":\"Blaise Delattre\"}],\" \",\"is a Postdoctoral Researcher in the TDSAI Lab, working with Prof. Yang Cao. He received his PhD in Computer Science from PSL University, where his research focused on certified adversarial robustness of deep neural networks, with contributions on Lipschitz-constrained architectures and randomized smoothing. His current interests focus on robustness and reliability of large language, vision–language, and other foundation models.\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"w-[5.9em] h-[5px] bg-gradient-to-r from-primary from-30% to-secondary mt-14 mb-6\"}]]}],[\"$\",\"section\",\"2\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"text-primary uppercase tracking-[0.2em] mb-2 font-semibold\",\"children\":[\"Tutorial \",2]}],[\"$\",\"h3\",null,{\"className\":\"font-bold text-2xl mb-2 text-gray-600 leading-9\",\"children\":\"Question Answering over Knowledge Bases in the Era of Large Language Models\"}],[\"$\",\"ul\",null,{\"className\":\"text-sm mt-6 mb-6 list-disc list-inside\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Venue:\"}],\" \",\"Sydney (in-person), Bali (broadcast)\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Sydney Time:\"}],\" \",\"Sat, 6 Dec 2025 13:00 - 14:00 AEDT (UTC+11)\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Bali Time:\"}],\" \",\"Sat, 6 Dec 2025 10:00 - 11:00 WITA (UTC+8)\"]}]]}],[\"$\",\"p\",null,{\"className\":\"\",\"children\":\"Knowledge Base Question Answering (KBQA) has emerged as a crucial paradigm for providing accurate, explainable, and domain-specific answers to natural language queries. With the rapid advancement of Large Language Models (LLMs), QA systems can leverage their powerful language understanding and generation capabilities. However, LLMs often struggle with hallucination, static knowledge, and limited interpretability. Integrating structured Knowledge Bases (KBs) addresses these limitations by providing explicit, updatable, and domain-specific factual knowledge. This tutorial provides an overview of KBQA in the era of LLMs. We introduce fundamental concepts of KBQA, discuss the strengths and limitations of LLMs and KBs, and survey state-of-the-art methods, including retrieval-augmented generation and knowledge integration approaches. Practical considerations, applications, and limitations are highlighted throughout.\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center space-x-2 mt-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-0 h-0 border-t-[0.6em] border-t-transparent border-l-[1em] border-gray-600 border-b-[0.6em] border-b-transparent\"}],[\"$\",\"h3\",null,{\"className\":\"font-bold text-xl text-gray-600\",\"children\":[\"Speaker\",\"\"]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"bg-gray-100 mt-4 rounded-xl min-w-[20rem]\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://jianzhongqi.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl\",\"children\":[\"$\",\"img\",null,{\"src\":\"/2025/images/people/Jianzhong-Qi.jpg\",\"alt\":\"Jianzhong Qi\",\"className\":\"w-32 h-32 rounded-tl-xl object-cover shadow-lg\"}]}],[\"$\",\"a\",null,{\"href\":\"https://jianzhongqi.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-bold text-[1.2em]\",\"children\":\"Jianzhong Qi\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-500 font-medium text-[0.95em]\",\"children\":\"The University of Melbourne\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 text-[0.9em] px-4 pb-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://jianzhongqi.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"hover:text-primary transition-colors duration-300\",\"children\":\"Jianzhong Qi\"}],\" \",\"is an Associate Professor at The University of Melbourne and an ARC Future Fellow. His research concerns fundamental algorithms for management of and knowledge discovery from structured and semi-structured data. He has served as a PC Chair for the Australasian Database  Conference in 2020, and he has served as an Area Chair, Senior PC member, and PC member for top machine learning and database venues such as ICML, NeurIPS, ICLR, SIGMOD, ICDE and WWW.\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"w-[5.9em] h-[5px] bg-gradient-to-r from-primary from-30% to-secondary mt-14 mb-6\"}]]}],[\"$\",\"section\",\"3\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"text-primary uppercase tracking-[0.2em] mb-2 font-semibold\",\"children\":[\"Tutorial \",3]}],[\"$\",\"h3\",null,{\"className\":\"font-bold text-2xl mb-2 text-gray-600 leading-9\",\"children\":\"Neural Network Reprogrammability: A Unified Framework for Parameter-Efficient Foundation Model Adaptation\"}],[\"$\",\"ul\",null,{\"className\":\"text-sm mt-6 mb-6 list-disc list-inside\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Venue:\"}],\" \",\"Bali (in-person), Sydney (broadcast)\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Sydney Time:\"}],\" \",\"Sat, 6 Dec 2025 14:00 - 15:00 AEDT (UTC+11)\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Bali Time:\"}],\" \",\"Sat, 6 Dec 2025 11:00 - 12:00 WITA (UTC+8)\"]}]]}],[\"$\",\"p\",null,{\"className\":\"\",\"children\":\"$b\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center space-x-2 mt-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-0 h-0 border-t-[0.6em] border-t-transparent border-l-[1em] border-gray-600 border-b-[0.6em] border-b-transparent\"}],[\"$\",\"h3\",null,{\"className\":\"font-bold text-xl text-gray-600\",\"children\":[\"Speaker\",\"\"]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"bg-gray-100 mt-4 rounded-xl min-w-[20rem]\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://fengliu90.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl\",\"children\":[\"$\",\"img\",null,{\"src\":\"/2025/images/people/Feng-Liu.jpeg\",\"alt\":\"Feng Liu\",\"className\":\"w-32 h-32 rounded-tl-xl object-cover shadow-lg\"}]}],[\"$\",\"a\",null,{\"href\":\"https://fengliu90.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-bold text-[1.2em]\",\"children\":\"Feng Liu\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-500 font-medium text-[0.95em]\",\"children\":\"The University of Melbourne\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 text-[0.9em] px-4 pb-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://fengliu90.github.io/\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"hover:text-primary transition-colors duration-300\",\"children\":\"Feng Liu\"}],\" \",\"is a Senior Lecturer in Machine Learning and ARC DECRA Fellow at The University of Melbourne, where he directs the Trustworthy Machine Learning and Reasoning Lab. He is also a Visiting Scientist at RIKEN AIP. His research focuses on hypothesis testing and trustworthy machine learning. He has served as an area chair for ICML, NeurIPS, ICLR, and AISTATS, and as an editor or action editor for several leading journals. His work has been recognized with the NeurIPS 2022 Outstanding Paper Award and multiple Outstanding Reviewer Awards.\"]}]]}]]}],[\"$\",\"div\",null,{\"className\":\"w-[5.9em] h-[5px] bg-gradient-to-r from-primary from-30% to-secondary mt-14 mb-6\"}]]}],[\"$\",\"section\",\"4\",{\"children\":[[\"$\",\"p\",null,{\"className\":\"text-primary uppercase tracking-[0.2em] mb-2 font-semibold\",\"children\":[\"Tutorial \",4]}],[\"$\",\"h3\",null,{\"className\":\"font-bold text-2xl mb-2 text-gray-600 leading-9\",\"children\":\"Optimizing Quality and Efficiency in Federated Learning\"}],[\"$\",\"ul\",null,{\"className\":\"text-sm mt-6 mb-6 list-disc list-inside\",\"children\":[[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Venue:\"}],\" \",\"Bali (in-person), Sydney (broadcast)\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Sydney Time:\"}],\" \",\"Sat, 6 Dec 2025 15:30 - 16:30 AEDT (UTC+11)\"]}],[\"$\",\"li\",null,{\"children\":[[\"$\",\"span\",null,{\"className\":\"font-semibold inline md:min-w-30 md:inline-block\",\"children\":\"Bali Time:\"}],\" \",\"Sat, 6 Dec 2025 12:30 - 13:30 WITA (UTC+8)\"]}]]}],[\"$\",\"p\",null,{\"className\":\"\",\"children\":\"Federated Learning (FL) faces critical challenges in model generalization and  Non-IID data, which impact both the quality and efficiency of the learned models. This talk will present some advancements to address these issues. We first introduce a reinforcement federated domain generalization method, which uses a reinforcement learning agent to dynamically optimize feature representation for superior performance on unseen data domains. Next, we present a method to create privacy-preserving client data, effectively mitigating data heterogeneity. Finally, we describe a classifier debiased federated learning framework that directly corrects classifier bias from Non-IID data. Together, these approaches form a cohesive strategy for building more robust, accurate, and efficient FL systems.\"}],[\"$\",\"div\",null,{\"className\":\"flex items-center space-x-2 mt-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-0 h-0 border-t-[0.6em] border-t-transparent border-l-[1em] border-gray-600 border-b-[0.6em] border-b-transparent\"}],[\"$\",\"h3\",null,{\"className\":\"font-bold text-xl text-gray-600\",\"children\":[\"Speaker\",\"\"]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-col\",\"children\":[[\"$\",\"div\",\"0\",{\"className\":\"bg-gray-100 mt-4 rounded-xl min-w-[20rem]\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://teacher.bupt.edu.cn/xuezhe/en/index.htm\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex items-center mb-2 mr-5 w-fit float-start border-gray-100 border-2 rounded-tl-xl\",\"children\":[\"$\",\"img\",null,{\"src\":\"/2025/images/people/Zhe-Xue.jpg\",\"alt\":\"Zhe Xue\",\"className\":\"w-32 h-32 rounded-tl-xl object-cover shadow-lg\"}]}],[\"$\",\"a\",null,{\"href\":\"https://teacher.bupt.edu.cn/xuezhe/en/index.htm\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"flex flex-col pt-5 pb-2 hover:text-primary transition-colors duration-300\",\"children\":[[\"$\",\"h4\",null,{\"className\":\"font-bold text-[1.2em]\",\"children\":\"Zhe Xue\"}],[\"$\",\"p\",null,{\"className\":\"text-gray-500 font-medium text-[0.95em]\",\"children\":\"Beijing University of Posts and Telecommunications\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-gray-600 text-[0.9em] px-4 pb-4\",\"children\":[[\"$\",\"a\",null,{\"href\":\"https://teacher.bupt.edu.cn/xuezhe/en/index.htm\",\"target\":\"_blank\",\"rel\":\"noopener\",\"className\":\"hover:text-primary transition-colors duration-300\",\"children\":\"Zhe Xue\"}],\" \",\"is a Professor at Beijing University of Posts and Telecommunications, specializing in data mining, multimodal learning, and federated learning. He has published many papers in top-tier journals and conferences such as ICML, NeurIPS, CVPR, AAAI, IJCAI, MM and WWW. His major honors include the IEEE CCIS Best Paper Award, IEEE BigComp Best Paper Award Runner-up, CCFAI Best Paper Award, and ChinaMM Best Student Paper Award.\"]}]]}]]}],false]}]]}]]}],[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],null,[\"$\",\"$Le\",null,{\"children\":[\"$Lf\",\"$L10\",[\"$\",\"$L11\",null,{\"promise\":\"$@12\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"s1a84tsxS8JDbe4564jH-\",{\"children\":[[\"$\",\"$L13\",null,{\"children\":\"$L14\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],null]}],false]],\"m\":\"$undefined\",\"G\":[\"$15\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"16:\"$Sreact.suspense\"\n17:I[4911,[],\"AsyncMetadata\"]\nd:[\"$\",\"$16\",null,{\"fallback\":null,\"children\":[\"$\",\"$L17\",null,{\"promise\":\"$@18\"}]}]\n"])</script><script>self.__next_f.push([1,"10:null\n"])</script><script>self.__next_f.push([1,"14:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nf:null\n"])</script><script>self.__next_f.push([1,"18:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Tutorials | ADC 2025\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Learn about the tutorials at ADC 2025.\"}],[\"$\",\"link\",\"2\",{\"rel\":\"manifest\",\"href\":\"/2025/manifest.json\",\"crossOrigin\":\"$undefined\"}],[\"$\",\"meta\",\"3\",{\"name\":\"creator\",\"content\":\"ADC2025 Committee\"}],[\"$\",\"meta\",\"4\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"link\",\"5\",{\"rel\":\"canonical\",\"href\":\"https://adc-conference.github.io/2025/program/tutorials\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:title\",\"content\":\"ADC 2025 - Australasian Database Conference\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:description\",\"content\":\"Welcome to the 36th Australasian Database Conference, ADC 2025. The Australasian Database Conference (ADC) series is an annual forum for sharing the latest research progresses and novel applications of database systems, data management, data mining and data analytics for researchers and practitioners in these areas from Australia, New Zealand and in the world.\"}],[\"$\",\"meta\",\"8\",{\"property\":\"og:url\",\"content\":\"https://adc-conference.github.io/2025\"}],[\"$\",\"meta\",\"9\",{\"property\":\"og:site_name\",\"content\":\"ADC 2025\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:locale\",\"content\":\"en_AU\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:image\",\"content\":\"https://adc-conference.github.io/2025/thumbnail.jpg\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:image:width\",\"content\":\"2124\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:image:height\",\"content\":\"1536\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:image:alt\",\"content\":\"ADC 2025 - Australasian Database Conference\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"16\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"17\",{\"name\":\"twitter:title\",\"content\":\"ADC 2025 - Australasian Database Conference\"}],[\"$\",\"meta\",\"18\",{\"name\":\"twitter:description\",\"content\":\"Welcome to the 36th Australasian Database Conference, ADC 2025. The Australasian Database Conference (ADC) series is an annual forum for sharing the latest research progresses and novel applications of database systems, data management, data mining and data analytics for researchers and practitioners in these areas from Australia, New Zealand and in the world.\"}],[\"$\",\"meta\",\"19\",{\"name\":\"twitter:image\",\"content\":\"https://adc-conference.github.io/2025/thumbnail.jpg\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:image:width\",\"content\":\"2124\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:image:height\",\"content\":\"1536\"}],[\"$\",\"meta\",\"22\",{\"name\":\"twitter:image:alt\",\"content\":\"ADC 2025 - Australasian Database Conference\"}],[\"$\",\"link\",\"23\",{\"rel\":\"icon\",\"href\":\"/2025/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"48x48\"}],[\"$\",\"link\",\"24\",{\"rel\":\"icon\",\"href\":\"/2025/icon0.svg?6301f139932b1e0e\",\"type\":\"image/svg+xml\",\"sizes\":\"any\"}],[\"$\",\"link\",\"25\",{\"rel\":\"icon\",\"href\":\"/2025/icon1.png?e3db09bd4030dcd9\",\"type\":\"image/png\",\"sizes\":\"96x96\"}],[\"$\",\"link\",\"26\",{\"rel\":\"apple-touch-icon\",\"href\":\"/2025/apple-icon.png?2a84e5a153a42d32\",\"type\":\"image/png\",\"sizes\":\"180x180\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"12:{\"metadata\":\"$18:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>